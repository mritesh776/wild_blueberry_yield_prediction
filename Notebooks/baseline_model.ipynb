{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Wild Blueberry Yield Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. [Description](#description)\n",
    "2. [Problem Statement](#problem-statement)\n",
    "3. [Loading necessary libraries](#loading-necessary-libraries)\n",
    "4. [Function Definations](#function-definations)\n",
    "5. [Reading in the Dataset](#reading-in-the-dataset)\n",
    "6. [Exploratory Descriptive Analysis(EDA)](#exploratory-descriptive-analysiseda)\n",
    "    1. [Basic Data Inspection](#basic-data-inspection)\n",
    "    2. [Descriptive Statistics](#descriptive-statistics)\n",
    "    3. [Duplicate Values](#duplicate-values)\n",
    "    4. [Missing Values](#missing-values)\n",
    "    5. [Unique Values](#unique-values)\n",
    "    6. [Exploring Target Variable](#exploring-target-variable)\n",
    "    7. [Data Visualization](#data-visualization)\n",
    "7. [Insights](#insights)\n",
    "8. [Preprocessing](#preprocessing)\n",
    "9. [Feature Engineering]()\n",
    "10. [Modeling]()\n",
    "11. [Hyperparameter Tuning]()\n",
    "12. [Explainable AI(XAI)]()\n",
    "13. [Dataframe Pipeline]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The dataset used for predictive modelling was generated by the Wild Blueberry Pollination Simulation Model, which is an open-source, spatially-explicit computer simulation program, that enables exploration of how various factors, including plant spatial arrangement, outcrossing and self-pollination, bee species compositions and weather conditions, in isolation and combination, affect pollination efficiency and yield of the wild blueberry agro-ecosystem. The simulation model has been validated by the field observation and experimental data collected in Maine USA and Canadian Maritimes during the last 30 years and now is a useful tool for hypothesis testing and theory development for wild blueberry pollination researches. This simulated data provides researchers who have actual data collected from field observation and those who wants to experiment the potential of machine learning algorithms response to real data and computer simulation modelling generated data as input for crop yield prediction models.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The target feature is ```yield``` which is a continuous variable. The task is to classify this variable based on the other 17 features.The evaluation metrics will be **RMSE** score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries\n",
    "- NumPy: A library for numerical operations in Python.\n",
    "- Pandas: A powerful library for data manipulation and analysis.\n",
    "- Matplotlib: A library for creating static, interactive, and animated visualizations in Python.\n",
    "- Seaborn: A data visualization library based on Matplotlib for making attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Checking the version of the library installed in the Environment. \n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "\n",
    "# Matplotlib plots appear directly within the notebook, enhancing the interactivity\n",
    "%matplotlib inline\n",
    "\n",
    "# Dark visual theme and 'pastel' color palette for Seaborn plots.\n",
    "sns.set_theme(style=\"dark\")\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "\n",
    "# Suppresssing non-critical warnings to maintain clean and uncluttered output for better readability.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns without truncation\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definations\n",
    "- Function prints the number of columns in a DataFrame and lists their names in square brackets, separated by commas.<br>\n",
    "Function calling: ```columns_in_a_dataframe(dataframe)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function prints the number of columns in a DataFrame and lists their names in square brackets, separated by commas. \n",
    "def columns_in_a_dataframe(dataframe):\n",
    "\n",
    "    dataframe_columns = dataframe.columns.tolist()\n",
    "    print(f\"Number of columns: {len(dataframe_columns)}\")\n",
    "    print(f\"{dataframe_columns}\\n\")\n",
    "\n",
    "\n",
    "# 2. Function distinguishes columns in a DataFrame based on their data types\n",
    "def distinguish_column_ac_to_datatype(dataframe):\n",
    "    data_types = {\n",
    "        'Numerical': ['number'],\n",
    "        'Categorical': ['category', 'object'],\n",
    "        'Datetime': ['datetime', 'datetime64[ns]']\n",
    "    }\n",
    "    \n",
    "    for dtype, dtype_list in data_types.items():\n",
    "        columns = dataframe.select_dtypes(include=dtype_list).columns.tolist()\n",
    "        if columns:\n",
    "            print(f\"Number of {dtype} columns: {len(columns)}\")\n",
    "            print(f\"{columns}\\n\")\n",
    "        else:\n",
    "            print(f\"No {dtype} column in your dataframe\")\n",
    "\n",
    "\n",
    "# 3. Function prints the number of missing value and percentage of missing values for each column having atleast one missing value\n",
    "def missing_values_table(dataframe):\n",
    "        \n",
    "    mis_val = dataframe.isnull().sum()\n",
    "    mis_val_percent = 100 * mis_val / len(dataframe)\n",
    "        \n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "    # Print some summary information\n",
    "    print (\"Your selected dataframe has \" + str(dataframe.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "        \n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "\n",
    "# 4. Function prints unique values for each column when unique values in that column is less than or equal to max_unique_values.\n",
    "def unique_values_per_column(dataframe, max_unique_values):\n",
    "    for column in dataframe.columns:\n",
    "        unique_values = dataframe[column].unique()\n",
    "        \n",
    "        if len(unique_values) <= max_unique_values:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(f\"Number of Unique values: {len(unique_values)}\")\n",
    "            print(f\"Unique values: {', '.join(map(str, unique_values))}\\n\")\n",
    "\n",
    "\n",
    "# 5. Function giving value count for each unique value sorted in descending order of occurance of each unique value\n",
    "def unique_value_with_count(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        print(f\"Column: {dataframe[column].value_counts().sort_values(ascending=False)}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# 6. Function plots histograms and boxplots for numerical columns in a DataFrame\n",
    "def plot_numerical_histogram_boxplot(dataframe):\n",
    "    numerical_columns = dataframe.select_dtypes(include=['number'])\n",
    "    \n",
    "    for column in numerical_columns.columns:\n",
    "        plt.figure(figsize=(15,6))\n",
    "\n",
    "        axes = plt.subplot(1,2,1)\n",
    "        sns.histplot(dataframe, x = column, bins = 20, color = 'steelblue', edgecolor = 'black')\n",
    "        axes.set_xlabel(column)\n",
    "        axes.set_ylabel('frequency')\n",
    "        axes.set_title(f'Histogram of {column}')\n",
    "\n",
    "        axes = plt.subplot(1,2,2)\n",
    "        sns.boxplot(dataframe, y= column, color= 'steelblue')\n",
    "        axes.set_ylabel(column)\n",
    "        axes.set_title(f'Boxplot of {column}')\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# 7. Function to plot countplots of all categorical variables in an ascending order of count of each unique variable with unique values less than or equal to the argument unique_value_limit \n",
    "def plot_categorical_countplots(dataframe, unique_value_limit=10):\n",
    "    categorical_columns = dataframe.select_dtypes(include=['object'])\n",
    "\n",
    "    for column in categorical_columns.columns:\n",
    "        unique_count = len(dataframe[column].unique())\n",
    "        if unique_count <= unique_value_limit:\n",
    "            plt.figure(figsize=(15, 6))\n",
    "            ax = sns.countplot(data=dataframe, x=column,order= dataframe[column].value_counts(ascending=True).index)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.title(f'Countplot of {column}')\n",
    "            plt.xlabel('')\n",
    "\n",
    "            total_count = len(dataframe[column])\n",
    "            \n",
    "            # Add text annotations for the count at the top and percentage in the middle of each bar\n",
    "            for p in ax.patches:\n",
    "                height = p.get_height()\n",
    "                height = int(height)\n",
    "                percentage = (height / total_count) * 100\n",
    "                x = p.get_x() + p.get_width() / 2.\n",
    "                y_top = height + 5  # Adjust the vertical position for the count\n",
    "                y_middle = height / 2\n",
    "                ax.annotate(f'{height}', \n",
    "                            (x, y_top),\n",
    "                            ha='center', va='bottom', fontsize=12, color='black')\n",
    "                ax.annotate(f'{percentage:.2f}%', \n",
    "                            (x, y_middle),\n",
    "                            ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# 8. Function to plot countplot of categorical variable in an ascending order of count of each unique variable\n",
    "def plot_single_categorical_countplot(dataframe, column_name):\n",
    "    if column_name not in dataframe.columns:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    unique_count = len(dataframe[column_name].unique())\n",
    "\n",
    "    if unique_count <= 20:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        ax = sns.countplot(data=dataframe, x=column_name, edgecolor='black', order=dataframe[column_name].value_counts(ascending=False).index)\n",
    "\n",
    "        ax.patch.set_edgecolor('black')\n",
    "        ax.patch.set_linewidth(2)\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(f'Countplot of {column_name}')\n",
    "        plt.xlabel('')\n",
    "\n",
    "        total_count = len(dataframe[column_name])\n",
    "\n",
    "        # Add text annotations for the count and percentage\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            height = int(height)\n",
    "            percentage = (height / total_count) * 100\n",
    "            x = p.get_x() + p.get_width() / 2.\n",
    "\n",
    "            if percentage < 5:\n",
    "                y_top_percentage = height + 10\n",
    "                ax.annotate(f'{percentage:.2f}%',\n",
    "                            (x, y_top_percentage),\n",
    "                            ha='center', va='bottom', fontsize=12, color='black')\n",
    "            else:\n",
    "                y_top = height + 10\n",
    "                ax.annotate(f'{height}',\n",
    "                            (x, y_top),\n",
    "                            ha='center', va='bottom', fontsize=12, color='black')\n",
    "                y_middle = height / 2\n",
    "                ax.annotate(f'{percentage:.2f}%',\n",
    "                            (x, y_middle),\n",
    "                            ha='center', va='center', fontsize=12, color='black')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Descriptive Analysis(EDA)\n",
    "\n",
    "### Basic Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of dataframe: {df_eda.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Columns of dataframe:\\n{df_eda.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinguish_column_ac_to_datatype(df_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Columns Statistics\n",
    "df_eda.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Columns Statistics\n",
    "df_eda.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of duplicate instances in the dataset: {df_eda.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(df_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_per_column(df_eda,20) #Function defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the Target variable\n",
    "print(df_eda[''].value_counts())\n",
    "\n",
    "# If the target variable is categorical\n",
    "plot_single_categorical_countplot(df_eda,'') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X]Histogram\n",
    "- [X]Boxplot\n",
    "- [X]Heatmap\n",
    "- [X]Countsplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize =(15,5))\n",
    "sns.heatmap(df_eda.corr(numeric_only = True),annot = True,cmap = \"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical_histogram_boxplot(df_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_countplots(df_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Pipeline\n",
    "\n",
    "This section provides a clear view of the data processing pipeline.\n",
    "\n",
    "1. **Initial Dataframe**\n",
    "\n",
    "- **Name:** `df`\n",
    "- **Description:** This is the initial dataframe containing the raw data.\n",
    "\n",
    "2. **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "- **Name:** `df_eda`\n",
    "- **Description:** A deep copy of the initial dataframe `df`, used for exploratory data analysis.\n",
    "\n",
    "3. **Heading**\n",
    "\n",
    "- **Name:** `df_`\n",
    "- **Description:** Description of the dataset\n",
    "\n",
    "\n",
    ". **Final Dataset for Modeling**\n",
    "\n",
    "- **Name:** `X_train_final`, `X_test_final`, `X_val_final`\n",
    "- **Description:** The final datasets used for machine learning modeling, including preprocessing steps like feature scaling, encoding, and feature selection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
